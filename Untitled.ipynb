{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"当前设备：\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j_bsvtSut6k",
        "outputId": "00a42556-2a71-4359-f1ab-159a71fa111f"
      },
      "id": "4j_bsvtSut6k",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "当前设备： cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "79a2080d-221d-4f5f-82f5-e0a27584d9ea",
      "metadata": {
        "collapsed": true,
        "id": "79a2080d-221d-4f5f-82f5-e0a27584d9ea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import lightning as L\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jvmbeLGduZ8",
        "outputId": "22548b43-3d23-44d1-f02b-e971c29ce2ae"
      },
      "id": "-jvmbeLGduZ8",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v8KoBa3i_ji",
        "outputId": "be86c0ad-4504-486d-d77d-e3a7a36a1c7e"
      },
      "id": "3v8KoBa3i_ji",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'   dogs-vs-cats.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/dogs-vs-cats.zip\"\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "DAihJhkkd2Mr"
      },
      "id": "DAihJhkkd2Mr",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76sRscuZiHg9",
        "outputId": "9baf22c6-2e67-4263-cfdb-a07504628745"
      },
      "id": "76sRscuZiHg9",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  test  test.zip  train  train.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "train_zip = \"/content/data/train.zip\"\n",
        "test_zip = \"/content/data/test.zip\"\n",
        "\n",
        "train_extract_path = \"/content/data/train\"\n",
        "test_extract_path = \"/content/data/test\"\n",
        "\n",
        "with zipfile.ZipFile(train_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(train_extract_path)\n",
        "\n",
        "with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(test_extract_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "lUeNuWe8jvmg"
      },
      "id": "lUeNuWe8jvmg",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/data/train\n",
        "!ls /content/data/test\n"
      ],
      "metadata": {
        "id": "0uleOEegk1XE"
      },
      "id": "0uleOEegk1XE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77827430-d28a-4cc4-b2ea-a7ac81f6a500",
      "metadata": {
        "id": "77827430-d28a-4cc4-b2ea-a7ac81f6a500"
      },
      "outputs": [],
      "source": [
        "class CatDogDataModule(L.LightningDataModule):\n",
        "    def __init__(self,data_dir, batch_size=64):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomRotation(30),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "             [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def setup(self,stage=None):\n",
        "        full_dataset = ImageFolder(root=os.path.join(self.data_dir,\"train\"),\n",
        "                                                     transform = self.transform)\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        val_size = len(full_dataset) - train_size\n",
        "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "         return DataLoader(self.train_dataset,\n",
        "                           batch_size=self.batch_size,\n",
        "                           shuffle=True,num_workers=0)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=2)\n",
        "\n",
        "class CatDog(L.LightningModule):\n",
        "    def __init__(self, lr=1e-3,input_shape=(3,64,64)):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        C, H, W = input_shape\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, C, H, W)\n",
        "            conv_out = self.conv(dummy)\n",
        "            n_size = conv_out.view(1, -1).size(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(n_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        self.loss_fn = nn.BCELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        preds = self(images)\n",
        "        labels = labels.to(preds.dtype).unsqueeze(1)\n",
        "        loss = self.loss_fn(preds, labels)\n",
        "        acc = ((preds > 0.5) == labels.bool()).float().mean()\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        labels = labels.float().unsqueeze(1)\n",
        "        preds = self(images)\n",
        "        loss = self.loss_fn(preds, labels)\n",
        "        acc = ((preds > 0.5) == labels.bool()).float().mean()\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4,weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"monitor\": \"val_loss\"\n",
        "            }\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0c49ce-f5c1-4b7a-b65b-e9be681a74f2",
      "metadata": {
        "id": "bc0c49ce-f5c1-4b7a-b65b-e9be681a74f2"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from torchvision.datasets import ImageFolder\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_module = CatDogDataModule(data_dir=\"/content/data\", batch_size=64)\n",
        "    model = CatDog(lr=0.001, input_shape=(3,224,224))\n",
        "\n",
        "    logger = TensorBoardLogger(\"lightning_logs\", name=\"catdog\")\n",
        "    checkpoint = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1)\n",
        "    early_stop = EarlyStopping(monitor=\"val_acc\", patience=5, mode=\"max\")\n",
        "\n",
        "    trainer = L.Trainer(\n",
        "        max_epochs=10,\n",
        "        accelerator='gpu',\n",
        "        devices=1,\n",
        "        precision=32,\n",
        "        logger=logger,\n",
        "        callbacks=[checkpoint, early_stop]\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, datamodule=data_module)\n",
        "\n",
        "    best_model_path = checkpoint.best_model_path\n",
        "    print(f\"Best checkpoint path: {best_model_path}\")\n",
        "    best_model = CatDog .load_from_checkpoint(best_model_path)\n",
        "    trainer.validate(best_model, datamodule=data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f82c9c-de69-486b-9b8b-4f81057c655b",
      "metadata": {
        "id": "06f82c9c-de69-486b-9b8b-4f81057c655b"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}